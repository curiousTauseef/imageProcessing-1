// Name: Maroof Mohammed Farooq// HW P2// Image Processing#include "headers.h"#include "imageData.h"#include "imageAlgorithms.h"#include "matrix.h"using namespace std;using namespace cv;Mat src, src_gray;Mat dst;int main(int argc, char *argv[]) {	// Define file pointer and variables	int BytesPerPixel;	int imageWidth;	int imageHeight;	int problemNumber;//----------------------------------------------------------------------------------------------------------------//	// Check for proper syntax	if (argc < 3) {		cout << "Syntax Error - Incorrect Parameter Usage:" << endl;		cout <<		"program_name input_image.raw output_image.raw [BytesPerPixel = 1] [imageWidth = 256] [imageHeight = 256]" <<		endl;		return 0;	}	// Check if image is grayscale or color	if (argc < 4) {		BytesPerPixel = 1;// default is grey image		imageHeight = 256;		imageWidth = 256;	}	else {		BytesPerPixel = atoi(argv[3]);		// Check if size is specified		if (argc >= 5) {			imageWidth = atoi(argv[4]);			imageHeight = atoi(argv[5]);		}		else {			imageHeight = 256;			imageWidth = 256;		}	}	problemNumber = atoi(argv[6]);//----------------------------------------------------------------------------------------------------------------//// input and output file names	string inputFileName = argv[1];	string outputFileName = argv[2];//----------------------------------------------------------------------------------------------------------------//// 1(a) Texture Classification	if (problemNumber == 1) {		// Reading additional arguments:		if(argc!=8){			cout<< "Incorrect number of arguments for problem 1!" <<endl;			exit(0);		}		int trainingSize = atoi(argv[7]);		// Read 12 training images		vector<imageData*> trainingImages;		vector<Mat> matFiles;		for(int i = 1; i<=trainingSize; i++){			imageData* trainImage = new imageData(BytesPerPixel,imageWidth,imageHeight);			trainImage->imageRead(("HW3 Images/P1/Texture"+to_string(i)+".raw").c_str());			Mat tempImage = trainImage->convertToMat();			trainingImages.push_back(trainImage);			matFiles.push_back((tempImage));		}		// Create object for image algorithms		imageAlgorithms lawsAlgorithm(trainingImages[0]);		// Step 1: Remove DC Component from filter		vector<matrix<int,double> > subtractedDCImages;		for_each(trainingImages.begin(),trainingImages.end(),[&](imageData* image){			subtractedDCImages.push_back(lawsAlgorithm.subtractDC(*image));		});		// Step 2: Create Law's filter		map<int,matrix<int,double> > filterBank = lawsAlgorithm.getLawsFilter();		// Step 3: Convolve laws filter with input image		map<int, matrix<int,double> > outputImages;		unordered_map<int, vector<double> > featureVectors;		featureVectors.reserve(trainingSize);		matrix<int,double> tempMatrix(imageHeight,imageWidth,BytesPerPixel);		double energyValue = 0;		int imageNumber = 0;		// Convolve all images		for_each(subtractedDCImages.begin(), subtractedDCImages.end(), [&](matrix<int,double> inputImage){			// Apply filter and calculate energy value			for_each(filterBank.begin(),filterBank.end(),[&](pair<int,matrix<int,double> > filter){				tempMatrix = lawsAlgorithm.filterApply(&inputImage,&get<1>(filter),"convolutionWithoutAbsolute");				energyValue = lawsAlgorithm.imageEnergy(tempMatrix);				featureVectors[imageNumber].push_back(energyValue);			});			imageNumber++;		});		// Step 4: Perform PCA:		// Create a feature matrix		Mat dataPoints(12,25,CV_32F);		for(int rowIndex = 0; rowIndex < 12; rowIndex++){			for(int columnIndex = 0; columnIndex < 25; columnIndex++){				dataPoints.at<float>(rowIndex,columnIndex) = featureVectors[rowIndex][columnIndex];			}		}		// Calculate PCA:		PCA pca(dataPoints, Mat(), CV_PCA_DATA_AS_ROW, 3);		Mat mean = pca.mean.clone();		Mat eigenvalues = pca.eigenvalues.clone();		Mat eigenvectors = pca.eigenvectors.clone();		// Project PCA points:		Mat projected;		pca.project(dataPoints,projected);		// Export PCA points to matlab		matrix<int,float> matlabOut(12,3,1);		matlabOut = matlabOut.mat2matrix<int,float>(projected);		matlabOut.printForMatlab();		// Step 5: Applying K means:		// K means Parameters		TermCriteria criteria = TermCriteria( CV_TERMCRIT_EPS + CV_TERMCRIT_ITER, 400, 0.3 );		int kValue = 4;		int numberOfAttempts = 5;		Mat labels,centers;		// Apply K means:		kmeans(projected ,kValue, labels, criteria, numberOfAttempts, KMEANS_RANDOM_CENTERS, centers);		cout<< labels << endl;	}//----------------------------------------------------------------------------------------------------------------//// 1(b) Texture Segmentation:	if(problemNumber == 2){		// Read input Image		imageData inputImage(BytesPerPixel,imageWidth,imageHeight);		inputImage.imageRead(inputFileName.c_str());		// Create image algorithms:		imageAlgorithms segmentation_pipeline(&inputImage);		// Subtract DC Components:		matrix<int,double> subtractedDC(imageHeight,imageWidth,BytesPerPixel);		subtractedDC = segmentation_pipeline.subtractDC(inputImage);		// Create Laws filter:		map<int,matrix<int,double> > filterBank = segmentation_pipeline.getLawsFilter();		// Convlolve all filters:		map<int, matrix<int,double> > outputImages;		matrix<int,double> tempMatrix(imageHeight,imageWidth,BytesPerPixel);		double energyValue = 0;		int index = 0;		for_each(filterBank.begin(),filterBank.end(),[&](pair<int,matrix<int,double>> filter){			outputImages[index++] = segmentation_pipeline.filterApply(&subtractedDC,&get<1>(filter),"convolutionWithoutAbsolute");		});		// Energy feature computation		int windowSize = 3;		int extendBy = floor(windowSize/2);		// Compute data points		Mat dataPoints(imageHeight*imageWidth,25,CV_32F);		for_each(outputImages.begin(),outputImages.end(),[&](pair<int,matrix<int,double>> imagePair){			dataPoints.col(get<0>(imagePair)).copyTo(segmentation_pipeline.energyPerPixel(&get<1>(imagePair),windowSize));		});		// Apply K means		TermCriteria criteria = TermCriteria( CV_TERMCRIT_EPS + CV_TERMCRIT_ITER, 400, 0.3 );		int kValue = 15;		int numberOfAttempts = 1;		Mat labels,centers;		// Apply K means:		kmeans(dataPoints ,kValue, labels, criteria, numberOfAttempts, KMEANS_RANDOM_CENTERS, centers);		// Output Labels		Mat outputImage(imageHeight,imageWidth,CV_8UC1);		unsigned char value = 0;		for(int rowIndex = 0; rowIndex < imageHeight; rowIndex++){			for(int columnIndex = 0; columnIndex < imageWidth; columnIndex++){				outputImage.at<unsigned char>(rowIndex,columnIndex) = (unsigned char)(labels.at<float>(rowIndex*imageWidth+columnIndex)*127);			}		}		//--------Pipeline Tester-----------////		subtractedDC.printForMatlab();//		exit(0);//		Mat test1 = inputImage.convertToMat();//		namedWindow("Image", WINDOW_AUTOSIZE);//		imshow("Image", test1);//		waitKey(0);//		exit(0);		//--------End-----------//		// Display image		namedWindow("Image", WINDOW_AUTOSIZE);		imshow("Image", outputImage);		waitKey(0);	}//----------------------------------------------------------------------------------------------------------------//// 2(a): Extraction and Description of Salient Points:	if(problemNumber ==4) {		Mat inputImage = imread(inputFileName, 0);		// Initialize Sift and Surf feature extractor:		SiftFeatureDetector siftDetector;		SurfFeatureDetector surfDetector;		vector <KeyPoint> keyPoints_sift, keyPoints_surf;		// Detect points of interest		siftDetector.detect(inputImage, keyPoints_sift);		surfDetector.detect(inputImage,keyPoints_surf);		// Display key points		Mat outputImage_sift, outputImage_surf;		drawKeypoints(inputImage, keyPoints_sift, outputImage_sift);		drawKeypoints(inputImage, keyPoints_surf, outputImage_surf);		// Save Images		imwrite("p2_a_output/"+outputFileName+"_sift.jpg",outputImage_sift);		imwrite("p2_a_output/"+outputFileName+"_surf.jpg",outputImage_surf);	}//----------------------------------------------------------------------------------------------------------------//// 2(b): Image matching	if (problemNumber==5){		Mat rav4_1 = imread(inputFileName+"rav4_1.jpg", 0);		Mat rav4_2 = imread(inputFileName+"rav4_2.jpg", 0);		Mat jeep = imread(inputFileName+"jeep.jpg", 0);		Mat bus = imread(inputFileName+"bus.jpg", 0);		// Initialize Sift and Surf feature extractor:		SiftFeatureDetector siftDetector;		SurfFeatureDetector surfDetector;		vector <KeyPoint> rav4_1_siftPoints, rav4_1_surfPoints;		vector <KeyPoint> rav4_2_siftPoints, rav4_2_surfPoints;		vector <KeyPoint> jeep_siftPoints, jeep_surfPoints;		vector <KeyPoint> bus_siftPoints, bus_surfPoints;		// Detect points of interest		siftDetector.detect(rav4_1, rav4_1_siftPoints);		surfDetector.detect(rav4_1,rav4_1_surfPoints);		siftDetector.detect(rav4_2, rav4_2_siftPoints);		surfDetector.detect(rav4_2,rav4_2_surfPoints);		siftDetector.detect(jeep, jeep_siftPoints);		surfDetector.detect(jeep,jeep_surfPoints);		siftDetector.detect(bus, bus_siftPoints);		surfDetector.detect(bus,bus_surfPoints);		// Display key points		Mat rav4_1_outputSift, rav4_1_outputSurf;		Mat rav4_2_outputSift, rav4_2_outputSurf;		drawKeypoints(rav4_1, rav4_1_siftPoints, rav4_1_outputSift);		drawKeypoints(rav4_1, rav4_1_surfPoints, rav4_1_outputSurf);		drawKeypoints(rav4_2, rav4_2_siftPoints, rav4_2_outputSift);		drawKeypoints(rav4_2, rav4_2_surfPoints, rav4_2_outputSurf);		// Save Images		imwrite("p2_b_output/rav_4_1_sift.jpg",rav4_1_outputSift);		imwrite("p2_b_output/rav_4_1_surf.jpg",rav4_1_outputSurf);		imwrite("p2_b_output/rav_4_2_sift.jpg",rav4_2_outputSift);		imwrite("p2_b_output/rav_4_2_surf.jpg",rav4_2_outputSurf);		// Calculate descriptors		SiftDescriptorExtractor siftExtractor;		SurfDescriptorExtractor surfExtractor;		// Descriptors		Mat rav4_1_siftDescriptors, rav4_1_surfDescriptors;		Mat rav4_2_siftDescriptors, rav4_2_surfDescriptors;		Mat jeep_siftDescriptors, jeep_surfDescriptors;		Mat bus_siftDescriptors, bus_surfDescriptors;		siftExtractor.compute(rav4_1,rav4_1_siftPoints,rav4_1_siftDescriptors);		surfExtractor.compute(rav4_1,rav4_1_surfPoints,rav4_1_surfDescriptors);		siftExtractor.compute(rav4_2,rav4_2_siftPoints,rav4_2_siftDescriptors);		surfExtractor.compute(rav4_2,rav4_2_surfPoints,rav4_2_surfDescriptors);		siftExtractor.compute(jeep,jeep_siftPoints,jeep_siftDescriptors);		surfExtractor.compute(jeep,jeep_surfPoints,jeep_surfDescriptors);		siftExtractor.compute(bus,bus_siftPoints,bus_siftDescriptors);		surfExtractor.compute(bus,bus_surfPoints,bus_surfDescriptors);		// Matching		BFMatcher matcher;//		Mat img_1 = imread( "HW3 Images/P2/rav4_2.jpg", 0 );//		Mat img_2 = imread( "HW3 Images/P2/rav4_1.jpg", 0 );////		//-- Step 1: Detect the keypoints using SURF Detector//		SiftFeatureDetector detector;//		vector<KeyPoint> keypoints_1, keypoints_2;//		detector.detect( img_1, keypoints_1 );//		detector.detect( img_2, keypoints_2 );////		//-- Step 2: Calculate descriptors (feature vectors)//		SiftDescriptorExtractor extractor;////		Mat descriptors_1, descriptors_2;////		extractor.compute( img_1, keypoints_1, descriptors_1 );//		extractor.compute( img_2, keypoints_2, descriptors_2 );////		//-- Step 3: Matching descriptor vectors using FLANN matcher//		BFMatcher matcher;//		vector< DMatch > matches;//		matcher.match( descriptors_1, descriptors_2, matches );////		double max_dist = 0; double min_dist = 100;////		//-- Quick calculation of max and min distances between keypoints//		for( int i = 0; i < descriptors_1.rows; i++ )//		{ double dist = matches[i].distance;//			if( dist < min_dist ) min_dist = dist;//			if( dist > max_dist ) max_dist = dist;//		}////		printf("-- Max dist : %f \n", max_dist );//		printf("-- Min dist : %f \n", min_dist );////		//-- Draw only "good" matches (i.e. whose distance is less than 2*min_dist,//		//-- or a small arbitary value ( 0.02 ) in the event that min_dist is very//		//-- small)//		//-- PS.- radiusMatch can also be used here.//		vector< DMatch > good_matches;////		for( int i = 0; i < descriptors_1.rows; i++ )//		{ if( matches[i].distance <= max(2*min_dist, 0.02) )//			{ good_matches.push_back( matches[i]); }//		}////		//-- Draw only "good" matches//		Mat img_matches;//		drawMatches( img_1, keypoints_1, img_2, keypoints_2,//					 good_matches, img_matches, Scalar::all(-1), Scalar::all(-1),//					 vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS );////		//-- Show detected matches//		imshow( "Good Matches", img_matches );////		for( int i = 0; i < (int)good_matches.size(); i++ )//		{ printf( "-- Good Match [%d] Keypoint 1: %d  -- Keypoint 2: %d  \n", i, good_matches[i].queryIdx, good_matches[i].trainIdx ); }////		waitKey(0);	}//----------------------------------------------------------------------------------------------------------------//// 3. Canny Edge detector:	if(problemNumber == 9){		// Read input image and convert to Mat		imageData inputImage(BytesPerPixel,imageWidth,imageHeight);		inputImage.imageRead(inputFileName.c_str());		Mat inputMatImage = inputImage.convertToMat();		//Set parameters of canny edge detector		int smootheningRadius = 5;		Mat grayImage(imageHeight,imageWidth,CV_8UC1);		cvtColor(inputMatImage,grayImage, CV_RGB2GRAY);		Mat outputMatImage(imageHeight,imageWidth,CV_8UC1);		// Apply Canny		Canny(grayImage,outputMatImage, 240,255,3,true);		// Display image		namedWindow("Image", WINDOW_AUTOSIZE);		imshow("Image", outputMatImage);		waitKey(0);	}	return 0;}//---------////		float data[10][2]=//				{{118.90323, 1088.7419},//				 {143.5, 1064.5},//				 {110, 1054},//				 {662, 645},//				 {650, 625.5},//				 {94, 363},//				 {60, 360},//				 {103.97369, 315.71054},//				 {70.5, 313},//				 {1466, 278.55554}};//////		Mat points(10,2, CV_32FC1,*data);//		cout << points << endl;//		Mat labels, centers;//		int k =4;//		kmeans(projected,k, labels,TermCriteria( CV_TERMCRIT_EPS+CV_TERMCRIT_ITER, 10, 1.0),3, KMEANS_PP_CENTERS, centers);//		kmeans(dataPoints,k,labels,TermCriteria(CV_TERMCRIT_ITER|CV_TERMCRIT_EPS, 10000, 0.0001),3, KMEANS_RANDOM_CENTERS, centers);////		cout << "labels: " << labels << endl;//		cout << "centers " << centers << endl;////		kmeans(dataPoints, 4, labels, TermCriteria(CV_TERMCRIT_ITER|CV_TERMCRIT_EPS, 10000, 0.0001),3, KMEANS_PP_CENTERS, centers);//		for_each(trainingImages.begin(),trainingImages.end(),[=](imageData* inputImage){////			inputImage->displayImage();//		});//		for(int i =0; i<12;i++){//			cout << eigenvalues.at<double>(i,0) << endl;//		}//		imageAlgorithms test(trainingImages[0]);//		matrix<int,unsigned char> testMat(128,128,1);//		testMat.setMatrixValues(trainingImages[0]->getPixelValues());//		matrix<int,double> convertedMat(128,128,1);//		convertedMat = testMat.converter<int,double>();//		matrix<int,double> outMat(128,128,1);//		outMat = test.filterApply(&convertedMat,&(filterBank[24]),"convolutionWithoutAbsolute");//		testMat = outMat.converter<int,unsigned char>();//		imageData testImage(1,128,128);//		testImage.setPixelValues(testMat.getMatrixValues());//		testImage.displayImage();//		trainingImages[0]->displayImage();